{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training diagram\n",
    "\n",
    "````{div} full-width\n",
    "```{mermaid}\n",
    "sequenceDiagram\n",
    "    autonumber\n",
    "    participant Agent\n",
    "    participant RL Method\n",
    "        Note left of RL Method: SVR, Actor-Critic...\n",
    "    participant Environment\n",
    "\n",
    "    loop Episode\n",
    "        Agent-->>+RL Method: Start training (Data, Initial State)\n",
    "        loop Step\n",
    "            RL Method-->>+Environment: Select an action following its exploration strategy\n",
    "            Environment-->>-RL Method: Return next state, action, reward and done flag\n",
    "            RL Method->>RL Method: Store transition to memory\n",
    "        end\n",
    "        RL Method->>RL Method: Update model\n",
    "        RL Method-->>-Agent: Returns episode reward\n",
    "    end\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Training an Agent powered by SVR model on 400 datasets split between regression (odd indexes) and binary classification problems (even indexes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from docs.workflows.utils.generate_training_datasets import generate_training_datasets\n",
    "from ostatslib.agents import Agent\n",
    "from ostatslib.reinforcement_learning_methods import SupportVectorRegression\n",
    "\n",
    "datasets = generate_training_datasets(400)\n",
    "agent = Agent(rl_method=SupportVectorRegression())\n",
    "for index, dataset in enumerate(datasets):\n",
    "    agent.train(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Agent analysis.\n",
    "\n",
    "- Binary classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: get_response_variable_type, reward: 1, next state features: [0 0 1 1]\n",
      "Action: LogisticRegressionCV(cv=5), reward: 1, next state features: [0.95290424 0.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "analysis = agent.analyze(datasets[0])\n",
    "\n",
    "for step in analysis:\n",
    "    print(f'Action: {step.result}, reward: {step.reward}, next state features: {step.state.features_vector}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: get_response_variable_type, reward: 1, next state features: [ 0  0 -1  1]\n",
      "Action: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7efe24750100>, reward: 1, next state features: [ 0.98989314  0.         -1.          1.        ]\n"
     ]
    }
   ],
   "source": [
    "analysis = agent.analyze(datasets[1])\n",
    "\n",
    "for step in analysis:\n",
    "    print(f'Action: {step.result}, reward: {step.reward}, next state features: {step.state.features_vector}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc31b72d76bb86a03669e931e818811fb2ab46ea94e9eb5815941aa084bb6329"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
