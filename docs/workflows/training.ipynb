{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training diagram\n",
    "\n",
    "````{div} full-width\n",
    "```{mermaid}\n",
    "sequenceDiagram\n",
    "    autonumber\n",
    "    participant Agent\n",
    "    participant RL Method\n",
    "        Note left of RL Method: SVR, Actor-Critic...\n",
    "    participant Environment\n",
    "\n",
    "    loop Episode\n",
    "        Agent-->>+RL Method: Start training (Data, Initial State)\n",
    "        loop Step\n",
    "            RL Method-->>+Environment: Select an action following its exploration strategy\n",
    "            Environment-->>-RL Method: Return next state, action, reward and done flag\n",
    "            RL Method->>RL Method: Store transition to memory\n",
    "        end\n",
    "        RL Method->>RL Method: Update model\n",
    "        RL Method-->>-Agent: Returns episode reward\n",
    "    end\n",
    "```\n",
    "````"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Training an Agent powered by SVR model on 6000 datasets split between binary classification, linear and poisson regression problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docs.workflows.utils.generate_training_datasets import generate_training_datasets\n",
    "datasets = generate_training_datasets(6000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ostatslib.agents import Agent\n",
    "from ostatslib.reinforcement_learning_methods import SupportVectorRegression\n",
    "\n",
    "agent = Agent(rl_method=SupportVectorRegression())\n",
    "for index, (dataset_type, dataset) in enumerate(datasets):\n",
    "    agent.train(dataset)\n",
    "\n",
    "agent.rl_method.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Agent analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting first dataset for each trained dataset type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datacooker.recipes import LogitRecipe, PoissonRecipe, Recipe\n",
    "\n",
    "logistic_regression_dataset = [dataset for dataset_type, dataset in datasets if dataset_type == LogitRecipe][0]\n",
    "linear_regression_dataset = [dataset for dataset_type, dataset in datasets if dataset_type == Recipe][0]\n",
    "poisson_regression_dataset = [dataset for (dataset_type, dataset) in datasets if dataset_type == PoissonRecipe][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Binary classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis executed at 2023-01-17 23:10:10.852220\n",
      "Final status is Complete\n",
      "Initial State known features:\n",
      "\n",
      "Steps:\n",
      "  Order  Step                             Reward  State Change\n",
      "-------  -----------------------------  --------  --------------------------\n",
      "      1  is_response_dichotomous_check  0.5       is_response_dichotomous  1\n",
      "      2  LogisticRegressionCV(cv=5)     0.778261  score  0.678261\n"
     ]
    }
   ],
   "source": [
    "analysis = agent.analyze(logistic_regression_dataset)\n",
    "print(analysis.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis executed at 2023-01-17 23:10:11.148657\n",
      "Final status is Complete\n",
      "Initial State known features:\n",
      "\n",
      "Steps:\n",
      "  Order  Step                             Reward  State Change\n",
      "-------  -----------------------------  --------  ---------------------------\n",
      "      1  is_response_dichotomous_check       0.5  is_response_dichotomous  -1\n",
      "      2  is_response_quantitative            0.5  is_response_quantitative  1\n",
      "      3  is_response_discrete_check          0.5  is_response_discrete  -1\n",
      "      4  DecisionTreeRegressor()             1    score  0.978191\n"
     ]
    }
   ],
   "source": [
    "analysis = agent.analyze(linear_regression_dataset)\n",
    "print(analysis.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Poisson Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis executed at 2023-01-17 23:10:11.381655\n",
      "Final status is Complete\n",
      "Initial State known features:\n",
      "\n",
      "Steps:\n",
      "  Order  Step                                                                                        Reward  State Change\n",
      "-------  ----------------------------------------------------------------------------------------  --------  -----------------------------------\n",
      "      1  is_response_dichotomous_check                                                             0.5       is_response_dichotomous  -1\n",
      "      2  is_response_quantitative                                                                  0.5       is_response_quantitative  1\n",
      "      3  is_response_discrete_check                                                                0.5       is_response_discrete  1\n",
      "      4  time_convertable_variable                                                                 0.5       time_convertable_variable\n",
      "      5  is_response_positive_values_only_check                                                    0.5       is_response_positive_values_only  1\n",
      "      6  get_log_rows_count                                                                        0.5       log_rows_count  0.24949\n",
      "      7  <statsmodels.genmod.generalized_linear_model.GLMResultsWrapper object at 0x7f0eb6ebace0>  0.878294  score  0.778294\n"
     ]
    }
   ],
   "source": [
    "analysis = agent.analyze(poisson_regression_dataset)\n",
    "print(analysis.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc31b72d76bb86a03669e931e818811fb2ab46ea94e9eb5815941aa084bb6329"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
