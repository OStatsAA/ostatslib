Traceback (most recent call last):
  File "/home/runner/work/ostatslib/ostatslib/.venv/lib/python3.11/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/home/runner/work/ostatslib/ostatslib/.venv/lib/python3.11/site-packages/nbclient/client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/work/ostatslib/ostatslib/.venv/lib/python3.11/site-packages/nbclient/util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/work/ostatslib/ostatslib/.venv/lib/python3.11/site-packages/nbclient/util.py", line 62, in just_run
    return loop.run_until_complete(coro)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.2/x64/lib/python3.11/asyncio/base_events.py", line 653, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/home/runner/work/ostatslib/ostatslib/.venv/lib/python3.11/site-packages/nbclient/client.py", line 663, in async_execute
    await self.async_execute_cell(
  File "/home/runner/work/ostatslib/ostatslib/.venv/lib/python3.11/site-packages/nbclient/client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/home/runner/work/ostatslib/ostatslib/.venv/lib/python3.11/site-packages/nbclient/client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
from ostatslib.agents import PPOAgent
from sklearn.datasets import make_classification
from pandas import DataFrame

import warnings
warnings.filterwarnings('ignore')

# loading trained agent
agent = PPOAgent('../trained_ppo_model')

# generating data
X, y = make_classification()
classification_data = DataFrame(X)
classification_data['result'] = y

# running analysis
classification_analysis = agent.analyze(classification_data)

# printing results
print(classification_analysis.summary())
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mKeyError[0m                                  Traceback (most recent call last)
Cell [0;32mIn[1], line 17[0m
[1;32m     14[0m classification_data[[38;5;124m'[39m[38;5;124mresult[39m[38;5;124m'[39m] [38;5;241m=[39m y
[1;32m     16[0m [38;5;66;03m# running analysis[39;00m
[0;32m---> 17[0m classification_analysis [38;5;241m=[39m [43magent[49m[38;5;241;43m.[39;49m[43manalyze[49m[43m([49m[43mclassification_data[49m[43m)[49m
[1;32m     19[0m [38;5;66;03m# printing results[39;00m
[1;32m     20[0m [38;5;28mprint[39m(classification_analysis[38;5;241m.[39msummary())

File [0;32m~/work/ostatslib/ostatslib/ostatslib/agents/agent.py:74[0m, in [0;36mAgent.analyze[0;34m(self, data, initial_state, max_steps)[0m
[1;32m     71[0m terminated [38;5;241m=[39m [38;5;28;01mFalse[39;00m
[1;32m     73[0m [38;5;28;01mfor[39;00m _ [38;5;129;01min[39;00m [38;5;28mrange[39m(max_steps):
[0;32m---> 74[0m     action [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_predict[49m[43m([49m[43mobservation[49m[43m)[49m
[1;32m     75[0m     observation, reward, terminated, truncated, info [38;5;241m=[39m environment[38;5;241m.[39mstep(action)
[1;32m     76[0m     analysis_steps[38;5;241m.[39mappend((reward, info))

File [0;32m~/work/ostatslib/ostatslib/ostatslib/agents/ppo_agent.py:35[0m, in [0;36mPPOAgent._predict[0;34m(self, observation)[0m
[1;32m     34[0m [38;5;28;01mdef[39;00m [38;5;21m_predict[39m([38;5;28mself[39m, observation: [38;5;28mdict[39m) [38;5;241m-[39m[38;5;241m>[39m ndarray:
[0;32m---> 35[0m     action, _ [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m__model[49m[38;5;241;43m.[39;49m[43mpredict[49m[43m([49m[43mobservation[49m[43m,[49m[43m [49m[43mdeterministic[49m[38;5;241;43m=[39;49m[38;5;28;43;01mTrue[39;49;00m[43m)[49m
[1;32m     36[0m     [38;5;28;01mreturn[39;00m action[[38;5;241m0[39m]

File [0;32m~/work/ostatslib/ostatslib/.venv/lib/python3.11/site-packages/stable_baselines3/common/base_class.py:542[0m, in [0;36mBaseAlgorithm.predict[0;34m(self, observation, state, episode_start, deterministic)[0m
[1;32m    522[0m [38;5;28;01mdef[39;00m [38;5;21mpredict[39m(
[1;32m    523[0m     [38;5;28mself[39m,
[1;32m    524[0m     observation: Union[np[38;5;241m.[39mndarray, Dict[[38;5;28mstr[39m, np[38;5;241m.[39mndarray]],
[0;32m   (...)[0m
[1;32m    527[0m     deterministic: [38;5;28mbool[39m [38;5;241m=[39m [38;5;28;01mFalse[39;00m,
[1;32m    528[0m ) [38;5;241m-[39m[38;5;241m>[39m Tuple[np[38;5;241m.[39mndarray, Optional[Tuple[np[38;5;241m.[39mndarray, [38;5;241m.[39m[38;5;241m.[39m[38;5;241m.[39m]]]:
[1;32m    529[0m [38;5;250m    [39m[38;5;124;03m"""[39;00m
[1;32m    530[0m [38;5;124;03m    Get the policy action from an observation (and optional hidden state).[39;00m
[1;32m    531[0m [38;5;124;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).[39;00m
[0;32m   (...)[0m
[1;32m    540[0m [38;5;124;03m        (used in recurrent policies)[39;00m
[1;32m    541[0m [38;5;124;03m    """[39;00m
[0;32m--> 542[0m     [38;5;28;01mreturn[39;00m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mpolicy[49m[38;5;241;43m.[39;49m[43mpredict[49m[43m([49m[43mobservation[49m[43m,[49m[43m [49m[43mstate[49m[43m,[49m[43m [49m[43mepisode_start[49m[43m,[49m[43m [49m[43mdeterministic[49m[43m)[49m

File [0;32m~/work/ostatslib/ostatslib/.venv/lib/python3.11/site-packages/stable_baselines3/common/policies.py:328[0m, in [0;36mBasePolicy.predict[0;34m(self, observation, state, episode_start, deterministic)[0m
[1;32m    320[0m [38;5;66;03m# TODO (GH/1): add support for RNN policies[39;00m
[1;32m    321[0m [38;5;66;03m# if state is None:[39;00m
[1;32m    322[0m [38;5;66;03m#     state = self.initial_state[39;00m
[1;32m    323[0m [38;5;66;03m# if episode_start is None:[39;00m
[1;32m    324[0m [38;5;66;03m#     episode_start = [False for _ in range(self.n_envs)][39;00m
[1;32m    325[0m [38;5;66;03m# Switch to eval mode (this affects batch norm / dropout)[39;00m
[1;32m    326[0m [38;5;28mself[39m[38;5;241m.[39mset_training_mode([38;5;28;01mFalse[39;00m)
[0;32m--> 328[0m observation, vectorized_env [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mobs_to_tensor[49m[43m([49m[43mobservation[49m[43m)[49m
[1;32m    330[0m [38;5;28;01mwith[39;00m th[38;5;241m.[39mno_grad():
[1;32m    331[0m     actions [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39m_predict(observation, deterministic[38;5;241m=[39mdeterministic)

File [0;32m~/work/ostatslib/ostatslib/.venv/lib/python3.11/site-packages/stable_baselines3/common/policies.py:224[0m, in [0;36mBaseModel.obs_to_tensor[0;34m(self, observation)[0m
[1;32m    222[0m observation [38;5;241m=[39m copy[38;5;241m.[39mdeepcopy(observation)
[1;32m    223[0m [38;5;28;01mfor[39;00m key, obs [38;5;129;01min[39;00m observation[38;5;241m.[39mitems():
[0;32m--> 224[0m     obs_space [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mobservation_space[49m[38;5;241;43m.[39;49m[43mspaces[49m[43m[[49m[43mkey[49m[43m][49m
[1;32m    225[0m     [38;5;28;01mif[39;00m is_image_space(obs_space):
[1;32m    226[0m         obs_ [38;5;241m=[39m maybe_transpose(obs, obs_space)

[0;31mKeyError[0m: 'response_inferred_dtype'
KeyError: 'response_inferred_dtype'

